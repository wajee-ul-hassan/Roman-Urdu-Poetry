{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "p1U9UK4yyxCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smU7jB5aWcyy",
        "outputId": "a4e36412-8129-4ade-b356-502b5463ebf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "O-sbkl5d6LAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing the data**"
      ],
      "metadata": {
        "id": "tBnj8IOvqMSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.The script cleans Roman Urdu text by replacing special characters with standard alphabets and prints before-and-after samples for inspection."
      ],
      "metadata": {
        "id": "pXibh-Le3pGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "# Replacement mapping dictionary (extended from earlier)\n",
        "replacement_mapping = {\n",
        "    'ñ': 'n', 'ā': 'a', 'ḳ': 'k', 'ġ': 'g', 'ī': 'i', 'ḍ': 'd',\n",
        "    'ḥ': 'h', 'ṣ': 's', 'ṭ': 't', 'ẓ': 'z', 'ū': 'u', 'ż': 'z',\n",
        "    'ṁ': 'm', 'ṙ': 'r', 'ʼ': '', 'ḷ': 'l', 'ê': 'e', 'é': 'e',\n",
        "    'ó': 'o', 'ô': 'o', 'í': 'i', 'â': 'a', 'ç': 'c', 'ã': 'a',\n",
        "    'è': 'e', 'à': 'a', 'ù': 'u', 'ü': 'u', 'ö': 'o', 'ì': 'i',\n",
        "    'ẖ': 'h', 'ẏ': 'y', 'ʿ': '', '.': '', ',': '', '’': '',\n",
        "    '!': '', '?': '', '“': '', '”': '', '–': '-', '—': '-',\n",
        "    '‘': '', 'µ': 'u', '@': 'at'\n",
        "}\n",
        "\n",
        "# Function to clean text by replacing special characters\n",
        "def replace_special_characters(text):\n",
        "    for special_char, standard_char in replacement_mapping.items():\n",
        "        text = text.replace(special_char, standard_char)\n",
        "    return text\n",
        "\n",
        "# Load the dataset (example CSV with a column named 'text')\n",
        "df = pd.read_csv('/content/drive/MyDrive/datasets/Roman-Urdu-Poetry.csv')\n",
        "\n",
        "# Show a sample before cleaning\n",
        "print(\"Before cleaning sample:\")\n",
        "print(df[['Poetry']].head(5))\n",
        "\n",
        "# Apply the cleaning function\n",
        "df['cleaned_text'] = df['Poetry'].apply(replace_special_characters)\n",
        "\n",
        "# Show a sample after cleaning\n",
        "print(\"\\nAfter cleaning sample:\")\n",
        "print(df[['cleaned_text']].head(5))\n",
        "\n",
        "# Save the cleaned dataset\n",
        "df.to_csv('/content/drive/MyDrive/datasets/Roman-Urdu-Poetry/cleaned_roman_urdu_dataset.csv', index=False)\n",
        "\n",
        "print(\"\\nDataset cleaned and saved successfully.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "oQuuTSBQvli0",
        "outputId": "32f7fb60-80ed-461c-937e-768b0cb612a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport pandas as pd\\n\\n# Replacement mapping dictionary (extended from earlier)\\nreplacement_mapping = {\\n    \\'ñ\\': \\'n\\', \\'ā\\': \\'a\\', \\'ḳ\\': \\'k\\', \\'ġ\\': \\'g\\', \\'ī\\': \\'i\\', \\'ḍ\\': \\'d\\',\\n    \\'ḥ\\': \\'h\\', \\'ṣ\\': \\'s\\', \\'ṭ\\': \\'t\\', \\'ẓ\\': \\'z\\', \\'ū\\': \\'u\\', \\'ż\\': \\'z\\',\\n    \\'ṁ\\': \\'m\\', \\'ṙ\\': \\'r\\', \\'ʼ\\': \\'\\', \\'ḷ\\': \\'l\\', \\'ê\\': \\'e\\', \\'é\\': \\'e\\',\\n    \\'ó\\': \\'o\\', \\'ô\\': \\'o\\', \\'í\\': \\'i\\', \\'â\\': \\'a\\', \\'ç\\': \\'c\\', \\'ã\\': \\'a\\',\\n    \\'è\\': \\'e\\', \\'à\\': \\'a\\', \\'ù\\': \\'u\\', \\'ü\\': \\'u\\', \\'ö\\': \\'o\\', \\'ì\\': \\'i\\',\\n    \\'ẖ\\': \\'h\\', \\'ẏ\\': \\'y\\', \\'ʿ\\': \\'\\', \\'.\\': \\'\\', \\',\\': \\'\\', \\'’\\': \\'\\',\\n    \\'!\\': \\'\\', \\'?\\': \\'\\', \\'“\\': \\'\\', \\'”\\': \\'\\', \\'–\\': \\'-\\', \\'—\\': \\'-\\',\\n    \\'‘\\': \\'\\', \\'µ\\': \\'u\\', \\'@\\': \\'at\\'\\n}\\n\\n# Function to clean text by replacing special characters\\ndef replace_special_characters(text):\\n    for special_char, standard_char in replacement_mapping.items():\\n        text = text.replace(special_char, standard_char)\\n    return text\\n\\n# Load the dataset (example CSV with a column named \\'text\\')\\ndf = pd.read_csv(\\'/content/drive/MyDrive/datasets/Roman-Urdu-Poetry.csv\\')\\n\\n# Show a sample before cleaning\\nprint(\"Before cleaning sample:\")\\nprint(df[[\\'Poetry\\']].head(5))\\n\\n# Apply the cleaning function\\ndf[\\'cleaned_text\\'] = df[\\'Poetry\\'].apply(replace_special_characters)\\n\\n# Show a sample after cleaning\\nprint(\"\\nAfter cleaning sample:\")\\nprint(df[[\\'cleaned_text\\']].head(5))\\n\\n# Save the cleaned dataset\\ndf.to_csv(\\'/content/drive/MyDrive/datasets/Roman-Urdu-Poetry/cleaned_roman_urdu_dataset.csv\\', index=False)\\n\\nprint(\"\\nDataset cleaned and saved successfully.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (example CSV with a column named 'text')\n",
        "data = pd.read_csv('/content/drive/MyDrive/datasets/Roman-Urdu-Poetry/cleaned_roman_urdu_dataset.csv')"
      ],
      "metadata": {
        "id": "LOF6eXyLx70f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess sentences\n",
        "def preprocess_english_data(data):\n",
        "    # Remove all non-alphabetic characters, keeping only letters a-z and A-Z\n",
        "    data = re.sub(r'[^a-zA-Z\\s]', '', data)  # Keeps only letters and spaces\n",
        "    # Remove extra spaces\n",
        "    data = re.sub(r'\\s+', ' ', data).strip()\n",
        "    #to lower case\n",
        "    data=data.lower()\n",
        "    return data"
      ],
      "metadata": {
        "id": "tpdiKzaTysS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)\n",
        "data['clean_data'] = data['cleaned_text'].apply(preprocess_english_data)\n",
        "data[['clean_data','cleaned_text']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "arEd69ckys3P",
        "outputId": "728ac66f-4b81-4096-c8f1-df2e96cdc7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          clean_data  \\\n",
              "0  aankh se duur na ho dil se utar jaega vaqt ka ...   \n",
              "1  ashiqi men mir jaise khvab mat dekha karo bavl...   \n",
              "2  ab aur kya kisi se marasim bahaen ham ye bhi b...   \n",
              "3  ab ke ham bichhe to shayad kabhi khvabon men m...   \n",
              "4  ab ke tajdidevafa ka nahin imkan janan yaad ky...   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  aankh se duur na ho dil se utar jaega \\nvaqt k...  \n",
              "1  ashiqi men 'mir' jaise khvab mat dekha karo \\n...  \n",
              "2  ab aur kya kisi se marasim baḌhaen ham \\nye bh...  \n",
              "3  ab ke ham bichhḌe to shayad kabhi khvabon men ...  \n",
              "4  ab ke tajdid-e-vafa ka nahin imkan janan \\nyaa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95e60e87-0c1f-454d-bb30-93e26693846a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_data</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aankh se duur na ho dil se utar jaega vaqt ka ...</td>\n",
              "      <td>aankh se duur na ho dil se utar jaega \\nvaqt k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ashiqi men mir jaise khvab mat dekha karo bavl...</td>\n",
              "      <td>ashiqi men 'mir' jaise khvab mat dekha karo \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ab aur kya kisi se marasim bahaen ham ye bhi b...</td>\n",
              "      <td>ab aur kya kisi se marasim baḌhaen ham \\nye bh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ab ke ham bichhe to shayad kabhi khvabon men m...</td>\n",
              "      <td>ab ke ham bichhḌe to shayad kabhi khvabon men ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ab ke tajdidevafa ka nahin imkan janan yaad ky...</td>\n",
              "      <td>ab ke tajdid-e-vafa ka nahin imkan janan \\nyaa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95e60e87-0c1f-454d-bb30-93e26693846a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95e60e87-0c1f-454d-bb30-93e26693846a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95e60e87-0c1f-454d-bb30-93e26693846a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8e0624b3-05b1-43a2-ae4b-acd8ea4efa9a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e0624b3-05b1-43a2-ae4b-acd8ea4efa9a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8e0624b3-05b1-43a2-ae4b-acd8ea4efa9a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data[['clean_data','cleaned_text']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"clean_data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ashiqi men mir jaise khvab mat dekha karo bavle ho jaoge mahtab mat dekha karo jasta jasta pah liya karna mazaminevafa par kitabeishq ka har baab mat dekha karo is tamashe men ulat jaati hain aksar kashtiyan dubne valon ko zereab mat dekha karo maikade men kya takalluf maikashi men kya hijab bazmesaqi men adab adab mat dekha karo ham se durveshon ke ghar aao to yaron ki tarah har jagah khaskhana o barfab mat dekha karo mangetange ki qabaen der tak rahti nahin yaar logon ke laqabalqab mat dekha karo tishnagi men lab bhigo lena bhi kaafi hai faraz jaam men sahba hai ya zahrab mat dekha karo\",\n          \"ab ke tajdidevafa ka nahin imkan janan yaad kya tujh ko dilaen tira paiman janan yunhi mausam ki ada dekh ke yaad aaya hai kis qadar jald badal jaate hain insan janan zindagi teri ata thi so tire naam ki hai ham ne jaise bhi basar ki tira ehsan janan dil ye kahta hai ki shayad hai fasurda tu bhi dil ki kya baat karen dil to hai nadan janan avval avval ki mohabbat ke nashe yaad to kar bepiye bhi tira chehra tha gulistan janan akhir akhir to ye aalam hai ki ab hosh nahin ragemina sulag utthi ki ragejan janan muddaton se yahi aalam na tavaqqo na umiid dil pukare hi chala jaata hai janan janan ham bhi kya saada the ham ne bhi samajh rakkha tha ghamedauran se juda hai ghamejanan janan ab ke kuchh aisi saji mahfileyaran janan sarbazanu hai koi sarbagareban janan har koi apni hi avaz se kaanp uthta hai har koi apne hi saae se hirasan janan jis ko dekho vahi zanjirbapa lagta hai shahr ka shahr hua dakhilezindan janan ab tira zikr bhi shayad hi ghazal men aae aur se aur hue dard ke unvan janan ham ki ruthi hui rut ko bhi mana lete the ham ne dekha hi na tha mausamehijran janan hosh aaya to sabhi khvab the reza reza jaise ute hue auraqepareshan janan\",\n          \"ab aur kya kisi se marasim bahaen ham ye bhi bahut hai tujh ko agar bhuul jaaen ham sahraezindagi men koi dusra na tha sunte rahe hain aap hi apni sadaen ham is zindagi men itni faraghat kise nasib itna na yaad aa ki tujhe bhuul jaaen ham tu itni dilzada to na thi ai shabefiraq aa tere raste men sitare lutaen ham vo log ab kahan hain jo kahte the kal faraz he he khudanakarda tujhe bhi rulaen ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ashiqi men 'mir' jaise khvab mat dekha karo \\nbavle ho jaoge mahtab mat dekha karo \\njasta jasta pa\\u1e0ch liya karna mazamin-e-vafa \\npar kitab-e-ishq ka har baab mat dekha karo \\nis tamashe men ulaT jaati hain aksar kashtiyan \\nDubne valon ko zer-e-ab mat dekha karo \\nmai-kade men kya takalluf mai-kashi men kya hijab \\nbazm-e-saqi men adab adab mat dekha karo \\nham se durveshon ke ghar aao to yaron ki tarah \\nhar jagah khas-khana o barfab mat dekha karo \\nmange-tange ki qabaen der tak rahti nahin \\nyaar logon ke laqab-alqab mat dekha karo \\ntishnagi men lab bhigo lena bhi kaafi hai 'faraz' \\njaam men sahba hai ya zahrab mat dekha karo\",\n          \"ab ke tajdid-e-vafa ka nahin imkan janan \\nyaad kya tujh ko dilaen tira paiman janan \\nyunhi mausam ki ada dekh ke yaad aaya hai \\nkis qadar jald badal jaate hain insan janan \\nzindagi teri ata thi so tire naam ki hai \\nham ne jaise bhi basar ki tira ehsan janan \\ndil ye kahta hai ki shayad hai fasurda tu bhi \\ndil ki kya baat karen dil to hai nadan janan \\navval avval ki mohabbat ke nashe yaad to kar \\nbe-piye bhi tira chehra tha gulistan janan \\nakhir akhir to ye aalam hai ki ab hosh nahin \\nrag-e-mina sulag uTThi ki rag-e-jan janan \\nmuddaton se yahi aalam na tavaqqo na umiid \\ndil pukare hi chala jaata hai janan janan \\nham bhi kya saada the ham ne bhi samajh rakkha tha \\ngham-e-dauran se juda hai gham-e-janan janan \\nab ke kuchh aisi saji mahfil-e-yaran janan \\nsar-ba-zanu hai koi sar-ba-gareban janan \\nhar koi apni hi avaz se kaanp uThta hai \\nhar koi apne hi saae se hirasan janan \\njis ko dekho vahi zanjir-ba-pa lagta hai \\nshahr ka shahr hua dakhil-e-zindan janan \\nab tira zikr bhi shayad hi ghazal men aae \\naur se aur hue dard ke unvan janan \\nham ki ruThi hui rut ko bhi mana lete the \\nham ne dekha hi na tha mausam-e-hijran janan \\nhosh aaya to sabhi khvab the reza reza \\njaise u\\u1e0cte hue auraq-e-pareshan janan\",\n          \"ab aur kya kisi se marasim ba\\u1e0chaen ham \\nye bhi bahut hai tujh ko agar bhuul jaaen ham \\nsahra-e-zindagi men koi dusra na tha \\nsunte rahe hain aap hi apni sadaen ham \\nis zindagi men itni faraghat kise nasib \\nitna na yaad aa ki tujhe bhuul jaaen ham \\ntu itni dil-zada to na thi ai shab-e-firaq \\naa tere raste men sitare luTaen ham \\nvo log ab kahan hain jo kahte the kal 'faraz' \\nhe he khuda-na-karda tujhe bhi rulaen ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = data['clean_data'].astype(str).tolist()"
      ],
      "metadata": {
        "id": "UobqkgwK3IHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Tokenization and Encoding"
      ],
      "metadata": {
        "id": "nqRX_J1p37uO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization"
      ],
      "metadata": {
        "id": "GoS_7zvUNLSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(data):\n",
        "  if isinstance(data,str):\n",
        "    return data.split()\n",
        "  else:\n",
        "    tokenized_data=[]\n",
        "    for sentence in data:\n",
        "      tokenized_data.append(sentence.split())\n",
        "    return tokenized_data"
      ],
      "metadata": {
        "id": "Mu3tPF-XNJ2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data=tokenize(corpus)\n",
        "print(tokenized_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2qFVWfxS-FI",
        "outputId": "dcdfa69c-aee4-49a2-d284-397ca79e3d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aankh', 'se', 'duur', 'na', 'ho', 'dil', 'se', 'utar', 'jaega', 'vaqt', 'ka', 'kya', 'hai', 'guzarta', 'hai', 'guzar', 'jaega', 'itna', 'manus', 'na', 'ho', 'khalvategham', 'se', 'apni', 'tu', 'kabhi', 'khud', 'ko', 'bhi', 'dekhega', 'to', 'dar', 'jaega', 'dubte', 'dubte', 'kashti', 'ko', 'uchhala', 'de', 'duun', 'main', 'nahin', 'koi', 'to', 'sahil', 'pe', 'utar', 'jaega', 'zindagi', 'teri', 'ata', 'hai', 'to', 'ye', 'jaane', 'vaala', 'teri', 'bakhshish', 'tiri', 'dahliz', 'pe', 'dhar', 'jaega', 'zabt', 'lazim', 'hai', 'magar', 'dukh', 'hai', 'qayamat', 'ka', 'faraz', 'zalim', 'ab', 'ke', 'bhi', 'na', 'roega', 'to', 'mar', 'jaega']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Vocab and word2idx *mapping*"
      ],
      "metadata": {
        "id": "gF1_k_YRNTVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vocab_word2idx(data):\n",
        "  vocab=set()\n",
        "  for sentence in data:\n",
        "    for word in sentence:\n",
        "      vocab.add(word)\n",
        "  vocab.add(\"<PAD>\")\n",
        "\n",
        "  word2idx={} #empty dictionary\n",
        "  idx=1\n",
        "  for word in vocab:\n",
        "    word2idx[word]=idx\n",
        "    idx+=1\n",
        "  word2idx[\"<PAD>\"] = 0  # Padding token\n",
        "  return word2idx,vocab"
      ],
      "metadata": {
        "id": "pKbTYpLnNTAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word2idx_mapping,vocab=vocab_word2idx(tokenized_data)\n"
      ],
      "metadata": {
        "id": "zHzxd2zn4SGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using the word2idx mapping now replacing the words with indices"
      ],
      "metadata": {
        "id": "N_mhkxeRUSZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tokens_to_indices(tokenized_data, word2idx):\n",
        "    indexed_data = []\n",
        "\n",
        "    for sentence in tokenized_data:\n",
        "        indexed_sentence = []\n",
        "\n",
        "        for word in sentence:\n",
        "            if word in word2idx:\n",
        "                indexed_sentence.append(word2idx[word])  # Add word index if found\n",
        "            else:\n",
        "                indexed_sentence.append(0)  # Assign 0 for unknown words\n",
        "\n",
        "        indexed_data.append(indexed_sentence)  # Append indexed sentence to the result\n",
        "\n",
        "    return indexed_data\n"
      ],
      "metadata": {
        "id": "05dpgzc0QDmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data=convert_tokens_to_indices(tokenized_data,word2idx_mapping)\n",
        "print(input_data[0])\n",
        "print(input_data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvsjpV8XVUu5",
        "outputId": "e618fd8d-60b5-4f7e-a473-0c666342b767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[103, 4671, 5668, 5243, 1866, 11272, 4671, 11636, 11365, 8425, 3854, 13240, 7436, 1939, 7436, 7369, 11365, 15895, 969, 5243, 1866, 14110, 4671, 7901, 11333, 12058, 10671, 1155, 15824, 8603, 7065, 13895, 11365, 4878, 4878, 1275, 1155, 15163, 3727, 6321, 12731, 9894, 9239, 7065, 16653, 14891, 11636, 11365, 10733, 9575, 8486, 7436, 7065, 454, 3400, 3925, 9575, 14671, 9091, 7557, 14891, 3749, 11365, 10750, 4705, 7436, 1570, 679, 7436, 1466, 3854, 10690, 10366, 3231, 2013, 15824, 5243, 482, 7065, 3376, 11365]\n",
            "[2106, 9708, 3374, 12934, 13073, 998, 4752, 8369, 12180, 1866, 9961, 8912, 998, 4752, 8369, 11960, 11960, 12081, 12371, 10929, 13404, 3869, 7487, 3854, 10187, 2854, 998, 4752, 8369, 14251, 7045, 9708, 4313, 1044, 13143, 4567, 15623, 9866, 6971, 1155, 11486, 998, 4752, 8369, 284, 9708, 13240, 5121, 7341, 9708, 13240, 7114, 14092, 9708, 16381, 16381, 998, 4752, 8369, 15694, 4671, 5565, 2013, 5948, 15433, 7065, 15517, 12501, 1030, 10187, 8539, 8727, 10954, 4431, 998, 4752, 8369, 5262, 12501, 12647, 10814, 9900, 6811, 9894, 15941, 16680, 2013, 6864, 998, 4752, 8369, 302, 9708, 5819, 10998, 15616, 15824, 12039, 7436, 10690, 15470, 9708, 2137, 7436, 6410, 6483, 998, 4752, 8369]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting data into context and target"
      ],
      "metadata": {
        "id": "aWsRxFotQA2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_data = []\n",
        "target_data = []\n",
        "\n",
        "for sentence in input_data:  # Iterate through each sentence in the input_data\n",
        "    for i in range(1, len(sentence)):  # Starting from index 1 to the end of the sentence\n",
        "        context_data.append(sentence[:i])  # Context: first i words (token indices)\n",
        "        target_data.append(sentence[i])   # Target: next word (token index)\n"
      ],
      "metadata": {
        "id": "Yj1Ul-IAP_FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context_data[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhU6Nk3gZC8L",
        "outputId": "53446db6-7f9a-4c87-90b1-50aa4ce2cf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103], [103, 4671]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_context_length = max(len(seq) for seq in context_data)\n"
      ],
      "metadata": {
        "id": "micfmKuXQJeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding Padding"
      ],
      "metadata": {
        "id": "mdd7YpS5QIr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''def pad_sequences(data, max_len, padding_value=0):\n",
        "    padded_data = []\n",
        "    for seq in data:\n",
        "        padded_seq = F.pad(torch.tensor(seq), (0, max_len - len(seq)), value=padding_value)\n",
        "        padded_data.append(padded_seq)\n",
        "    return torch.stack(padded_data)'''\n"
      ],
      "metadata": {
        "id": "Px4IYzqNQM3_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9fbb2c10-f509-4024-fcbc-5b0fe9826e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def pad_sequences(data, max_len, padding_value=0):\\n    padded_data = []\\n    for seq in data:\\n        padded_seq = F.pad(torch.tensor(seq), (0, max_len - len(seq)), value=padding_value)\\n        padded_data.append(padded_seq)\\n    return torch.stack(padded_data)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 100  # Limit sequence length to 100\n",
        "\n",
        "def pad_sequences(data, max_len, padding_value=0):\n",
        "    padded_data = []\n",
        "    for seq in data:\n",
        "        truncated_seq = seq[:max_len]  # Truncate sequences longer than max_len\n",
        "        padded_seq = F.pad(torch.tensor(truncated_seq), (0, max_len - len(truncated_seq)), value=padding_value)\n",
        "        padded_data.append(padded_seq)\n",
        "    return torch.stack(padded_data)\n"
      ],
      "metadata": {
        "id": "8O5SO_h0j5yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "GZJgbHoMuW7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusting context data with new max sequence length\n",
        "padded_context_data = pad_sequences(context_data, max_len=max_seq_len, padding_value=0)\n",
        "print(\"Sample padded context:\", padded_context_data[:2])\n",
        "print(\"Sample target data:\", target_data[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKb0ND2WQVzf",
        "outputId": "b903d255-ad2d-4f9c-88d3-bfc6f00ea1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample padded context: tensor([[ 103,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0],\n",
            "        [ 103, 4671,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0]])\n",
            "Sample target data: [4671, 5668]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After creating word2idx_mapping and vocab\n",
        "idx2word = {idx: word for word, idx in word2idx_mapping.items()}"
      ],
      "metadata": {
        "id": "g3oB1qOtmkaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Preparing Dataset"
      ],
      "metadata": {
        "id": "E9U1ikkf5VVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoetryDataset(Dataset):\n",
        "    def __init__(self, context_data, target_data):\n",
        "        self.context_data = context_data\n",
        "        self.target_data = target_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.context_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.context_data[idx], self.target_data[idx]\n"
      ],
      "metadata": {
        "id": "XRmsTZEo5WPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset\n",
        "dataset = PoetryDataset(padded_context_data, target_data)"
      ],
      "metadata": {
        "id": "uzuTqY9yR563"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "batch_size = 128\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "-33ftiCBSU_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "ctISl4nZch9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Architecture"
      ],
      "metadata": {
        "id": "whqmdXJ8Skt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoetryGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(PoetryGenerator, self).__init__()\n",
        "\n",
        "        # Embedding Layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # GRU Layer (2 layers)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True,dropout=0.3)\n",
        "\n",
        "        # Fully connected layer to predict next word\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get word embeddings for input\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Pass through GRU\n",
        "        gru_out, hidden = self.gru(embedded)\n",
        "\n",
        "        # Predict next word using the last hidden state\n",
        "        out = self.fc(gru_out[:, -1, :])  # Use the last time step\n",
        "        return out"
      ],
      "metadata": {
        "id": "W-n9Zo9QSahn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "output_dim = (len(vocab)+1)  # Vocabulary size\n",
        "model = PoetryGenerator(vocab_size=output_dim, embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=output_dim)"
      ],
      "metadata": {
        "id": "ywPIvVYHSvyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f152c5d-b29f-48ec-e7c4-6ab211aa7330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpVO9PWDTrim",
        "outputId": "83fa86f5-eda5-46e6-e55a-b78c7eec83fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PoetryGenerator(\n",
              "  (embedding): Embedding(16764, 128)\n",
              "  (gru): GRU(128, 256, batch_first=True, dropout=0.3)\n",
              "  (fc): Linear(in_features=256, out_features=16764, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "CNPhKVo4S29e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "HT_Qa8wjUkok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJGljCULvdUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7z92rGkrvH6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the Model"
      ],
      "metadata": {
        "id": "sWR05wjOTgxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Loop through batches to print input shapes\n",
        "for epoch in range(1):  # Only running for 1 epoch to check the inputs\n",
        "    for context_batch, target_batch in dataloader:\n",
        "        print(f\"Context batch shape: {context_batch.shape}\")\n",
        "        print(f\"Target batch shape: {target_batch.shape}\")\n",
        "        # You can also print the actual values of the batches if needed\n",
        "        print(f\"Context batch: {context_batch}\")\n",
        "        print(f\"Target batch: {target_batch}\")\n",
        "        print(\"-\" * 50)  # Divider for readability\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "MxcapWMOV7SN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "b57825c6-39c4-4e61-9aa8-d3e352705b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Loop through batches to print input shapes\\nfor epoch in range(1):  # Only running for 1 epoch to check the inputs\\n    for context_batch, target_batch in dataloader:\\n        print(f\"Context batch shape: {context_batch.shape}\")\\n        print(f\"Target batch shape: {target_batch.shape}\")\\n        # You can also print the actual values of the batches if needed\\n        print(f\"Context batch: {context_batch}\")\\n        print(f\"Target batch: {target_batch}\")\\n        print(\"-\" * 50)  # Divider for readability\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "epochs = 10\n",
        "patience = 3  # Stop if no improvement for 3 epochs\n",
        "best_train_loss = float('inf')\n",
        "early_stop_counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (context_batch, target_batch) in enumerate(dataloader):\n",
        "        context_batch, target_batch = context_batch.cuda(), target_batch.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(context_batch)\n",
        "        loss = criterion(output, target_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # **Early Stopping Check**\n",
        "    if avg_train_loss < best_train_loss:\n",
        "        best_train_loss = avg_train_loss\n",
        "        early_stop_counter = 0  # Reset counter\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        print(f\"No improvement. Early stop counter: {early_stop_counter}/{patience}\")\n",
        "\n",
        "    if early_stop_counter >= patience:\n",
        "        print(\"Early stopping triggered. Training stopped.\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "NtEofOhFS5en",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad906d2-7033-4b7b-f44b-5ad93f37324b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 3.2598\n",
            "Epoch 2/10, Training Loss: 3.2253\n",
            "Epoch 3/10, Training Loss: 3.2033\n",
            "Epoch 4/10, Training Loss: 3.2084\n",
            "No improvement. Early stop counter: 1/3\n",
            "Epoch 5/10, Training Loss: 3.1843\n",
            "Epoch 6/10, Training Loss: 3.1665\n",
            "Epoch 7/10, Training Loss: 3.1501\n",
            "Epoch 8/10, Training Loss: 3.1408\n",
            "Epoch 9/10, Training Loss: 3.1370\n",
            "Epoch 10/10, Training Loss: 3.1230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the model"
      ],
      "metadata": {
        "id": "54n2CFN5TjoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_with_temperature(output_logits, temperature=1.0):\n",
        "    \"\"\"Apply temperature to the output logits and sample a token.\"\"\"\n",
        "    probabilities = torch.nn.functional.softmax(output_logits / temperature, dim=-1)\n",
        "    return torch.multinomial(probabilities, num_samples=1).item()\n",
        "\n",
        "def generate_poetry_with_temperature(start_word, model, word2idx, idx2word, max_length=50, temperature=1.0):\n",
        "    model.eval()\n",
        "\n",
        "    # Convert start word to index\n",
        "    input_seq = torch.tensor([word2idx[start_word]]).unsqueeze(0).cuda()  # Add batch dimension\n",
        "    generated = [start_word]\n",
        "\n",
        "    # Generate words one at a time\n",
        "    for _ in range(max_length):\n",
        "        output = model(input_seq)  # Get model output\n",
        "        predicted_idx = sample_with_temperature(output, temperature)  # Apply temperature sampling\n",
        "\n",
        "        # Get the predicted word using the idx2word dictionary\n",
        "        predicted_word = idx2word[predicted_idx]\n",
        "\n",
        "        generated.append(predicted_word)\n",
        "\n",
        "        # Update input sequence for next prediction\n",
        "        input_seq = torch.tensor([predicted_idx]).unsqueeze(0).cuda()\n",
        "\n",
        "    return ' '.join(generated)\n"
      ],
      "metadata": {
        "id": "HXKsE7FXTf3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_word = \"dil\"  # Starting word\n",
        "temperature = 0.8    # Adjust temperature for randomness\n",
        "generated_poetry = generate_poetry_with_temperature(start_word, model, word2idx_mapping, idx2word, max_length=20, temperature=temperature)\n",
        "print(generated_poetry)"
      ],
      "metadata": {
        "id": "Fy27rYviPz1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9984215b-f4ae-4081-c561-eb6ea8f7a95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dil ye duniya dushman dulai jununalamat qasam yadgar aankh bhala baag dardepinhan bhige chunanche baghaireyakdilebemuddaa uthiye hudikhvanon khul bemuhaba muskuraungi bharam\n"
          ]
        }
      ]
    }
  ]
}